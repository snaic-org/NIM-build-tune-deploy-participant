{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# NIM Workshop Setup Guide\n",
        "\n",
        "Welcome to the NVIDIA NIM Workshop! This notebook will help you set up everything needed for working with **Llama 3.1 8B Instruct**.\n",
        "\n",
        "## üìã Quick Start\n",
        "\n",
        "1. **Run cell 1**: Set up your API keys\n",
        "2. **Run cell 2**: Check prerequisites  \n",
        "3. **Run cell 3**: Download Llama 3.1 8B model\n",
        "4. **Run cell 4**: Verify setup\n",
        "\n",
        "## ü§ñ Model Information\n",
        "\n",
        "**Llama 3.1 8B Instruct** (~15GB)\n",
        "- Standard NeMo format compatible with training scripts\n",
        "\n",
        "## üõ†Ô∏è Prerequisites\n",
        "\n",
        "- **NGC Account**: Free account at [ngc.nvidia.com](https://ngc.nvidia.com)\n",
        "- **NGC API Key**: Generate at [ngc.nvidia.com/setup/api-key](https://ngc.nvidia.com/setup/api-key)\n",
        "- **NVIDIA API Key**: For cloud NIMs from [build.nvidia.com](https://build.nvidia.com)\n",
        "- **Docker**: For local NIM deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 1: Set Up Your API Keys\n",
        "\n",
        "You'll need two API keys for this workshop:\n",
        "\n",
        "1. **NGC API Key** - To download the model\n",
        "2. **NVIDIA API Key** - To use cloud-hosted NIMs\n",
        "\n",
        "Run the cell below and enter your keys when prompted:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîê API Key Setup\n",
            "\n",
            "Enter your NGC API Key (for model downloads):\n",
            "Get one at: https://ngc.nvidia.com/setup/api-key\n",
            "\n",
            "Enter your NVIDIA API Key (for cloud NIMs):\n",
            "Get one at: https://build.nvidia.com\n",
            "\n",
            "‚úÖ API keys configured!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "print(\"üîê API Key Setup\\n\")\n",
        "\n",
        "# Get NGC API Key\n",
        "print(\"Enter your NGC API Key (for model downloads):\")\n",
        "print(\"Get one at: https://ngc.nvidia.com/setup/api-key\")\n",
        "ngc_key = getpass.getpass(\"NGC API Key: \")\n",
        "\n",
        "# Get NVIDIA API Key for cloud NIMs\n",
        "print(\"\\nEnter your NVIDIA API Key (for cloud NIMs):\")\n",
        "print(\"Get one at: https://build.nvidia.com\")\n",
        "nvidia_key = getpass.getpass(\"NVIDIA API Key: \")\n",
        "\n",
        "# Save to environment\n",
        "os.environ['NGC_API_KEY'] = ngc_key\n",
        "os.environ['NGC_CLI_API_KEY'] = ngc_key  # New environment variable name\n",
        "os.environ['NVIDIA_API_KEY'] = nvidia_key\n",
        "\n",
        "# Save to .env file\n",
        "with open('.env', 'w') as f:\n",
        "    f.write(f\"NGC_API_KEY={ngc_key}\\n\")\n",
        "    f.write(f\"NGC_CLI_API_KEY={ngc_key}\\n\")\n",
        "    f.write(f\"NVIDIA_API_KEY={nvidia_key}\\n\")\n",
        "\n",
        "print(\"\\n‚úÖ API keys configured!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 2: Check Prerequisites\n",
        "\n",
        "Let's verify all required tools are installed:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Checking prerequisites...\n",
            "\n",
            "‚úÖ Docker: Docker version 27.3.1, build ce12230\n",
            "‚úÖ NGC CLI: NGC CLI 3.160.1\n",
            "‚úÖ GPU: NVIDIA A100-SXM4-40GB\n",
            "‚úÖ Disk space: 193 GB free\n",
            "\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "print(\"üîç Checking prerequisites...\\n\")\n",
        "\n",
        "# 1. Check Docker\n",
        "try:\n",
        "    docker_version = subprocess.check_output(['docker', '--version'], text=True).strip()\n",
        "    print(f\"‚úÖ Docker: {docker_version}\")\n",
        "except:\n",
        "    print(\"‚ùå Docker: Not installed - get it from https://docs.docker.com/get-docker/\")\n",
        "\n",
        "# 2. Check/Install NGC CLI\n",
        "if os.path.exists('ngc-cli/ngc'):\n",
        "    result = subprocess.run(['./ngc-cli/ngc', '--version'], capture_output=True, text=True)\n",
        "    if result.returncode == 0:\n",
        "        print(f\"‚úÖ NGC CLI: {result.stdout.strip()}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  NGC CLI found but not working\")\n",
        "else:\n",
        "    print(\"üì• Installing NGC CLI...\")\n",
        "    os.system('wget -q https://ngc.nvidia.com/downloads/ngccli_linux.zip')\n",
        "    os.system('unzip -q ngccli_linux.zip')\n",
        "    os.system('chmod +x ngc-cli/ngc')\n",
        "    os.system('rm ngccli_linux.zip')\n",
        "    print(\"‚úÖ NGC CLI installed\")\n",
        "\n",
        "# 3. Check GPU (optional)\n",
        "try:\n",
        "    gpu = subprocess.check_output(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], text=True).strip()\n",
        "    print(f\"‚úÖ GPU: {gpu}\")\n",
        "except:\n",
        "    print(\"‚ÑπÔ∏è  No GPU detected (you can still use cloud NIMs)\")\n",
        "\n",
        "# 4. Check disk space\n",
        "free_gb = shutil.disk_usage(\"/\").free // (2**30)\n",
        "print(f\"‚úÖ Disk space: {free_gb} GB free\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 3: Download Llama 3.1 8B Model and NIM Container\n",
        "\n",
        "This will download:\n",
        "- **Llama 3.1 8B Instruct** (~15 GB) - The model for LoRA fine-tuning\n",
        "- **NIM Docker Container** - For local deployment\n",
        "\n",
        "‚è±Ô∏è Takes 10-30 minutes depending on internet speed\n",
        "\n",
        "### üìù Note about NGC CLI Output\n",
        "The NGC CLI shows detailed progress information. Don't worry about all the progress bars and symbols - just look for:\n",
        "- `Download status: Completed` - This means success!\n",
        "- The download summary at the bottom shows total files and size transferred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Downloading workshop assets...\n",
            "\n",
            "üì• Step 1: Checking Docker container...\n",
            "üì• Pulling NIM Docker container...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "latest: Pulling from nim/meta/llama-3.1-8b-instruct\n",
            "8a49af5f9845: Pulling fs layer\n",
            "5a7e430f96ec: Pulling fs layer\n",
            "dc8e02c573d5: Pulling fs layer\n",
            "f59d6eb2c245: Pulling fs layer\n",
            "69a2b9c38e00: Pulling fs layer\n",
            "4397f0d4f59f: Pulling fs layer\n",
            "a86d164c64ba: Pulling fs layer\n",
            "4e9f661082fc: Pulling fs layer\n",
            "bec80a6b3a0e: Pulling fs layer\n",
            "ff6c6c701902: Pulling fs layer\n",
            "38ed7fbe6701: Pulling fs layer\n",
            "bdb7462cbb97: Pulling fs layer\n",
            "3f955f899066: Pulling fs layer\n",
            "474075394bf2: Pulling fs layer\n",
            "27a2be24bf5e: Pulling fs layer\n",
            "fb00c809bb91: Pulling fs layer\n",
            "22e12f30f4dd: Pulling fs layer\n",
            "459dee64b7ed: Pulling fs layer\n",
            "38c04d3213e1: Pulling fs layer\n",
            "988fc097120c: Pulling fs layer\n",
            "899a1f93590a: Pulling fs layer\n",
            "4397f0d4f59f: Waiting\n",
            "b1fa02a3ce23: Pulling fs layer\n",
            "38ed7fbe6701: Waiting\n",
            "ed2758f68444: Pulling fs layer\n",
            "5cce4eb8ba0e: Pulling fs layer\n",
            "a86d164c64ba: Waiting\n",
            "a06c0a98fdc6: Pulling fs layer\n",
            "bdb7462cbb97: Waiting\n",
            "6a2923762427: Pulling fs layer\n",
            "4f4fb700ef54: Pulling fs layer\n",
            "4e9f661082fc: Waiting\n",
            "3f955f899066: Waiting\n",
            "2b210285da11: Pulling fs layer\n",
            "bec80a6b3a0e: Waiting\n",
            "f59d6eb2c245: Waiting\n",
            "5bc822689f39: Pulling fs layer\n",
            "ff6c6c701902: Waiting\n",
            "474075394bf2: Waiting\n",
            "ed2758f68444: Waiting\n",
            "10656710b432: Pulling fs layer\n",
            "27a2be24bf5e: Waiting\n",
            "0d157bd1c518: Pulling fs layer\n",
            "5cce4eb8ba0e: Waiting\n",
            "ea623811982e: Pulling fs layer\n",
            "fb00c809bb91: Waiting\n",
            "b1fa02a3ce23: Waiting\n",
            "a06c0a98fdc6: Waiting\n",
            "22e12f30f4dd: Waiting\n",
            "da3897cfef4f: Pulling fs layer\n",
            "5bc822689f39: Waiting\n",
            "6c46f635d9bf: Pulling fs layer\n",
            "459dee64b7ed: Waiting\n",
            "6a2923762427: Waiting\n",
            "10656710b432: Waiting\n",
            "cd9c6368b760: Pulling fs layer\n",
            "69a2b9c38e00: Waiting\n",
            "38c04d3213e1: Waiting\n",
            "988fc097120c: Waiting\n",
            "f440049522de: Pulling fs layer\n",
            "2b210285da11: Waiting\n",
            "4f4fb700ef54: Waiting\n",
            "4f87f4428c37: Pulling fs layer\n",
            "899a1f93590a: Waiting\n",
            "ea623811982e: Waiting\n",
            "da3897cfef4f: Waiting\n",
            "f440049522de: Waiting\n",
            "0d157bd1c518: Waiting\n",
            "8c4218ff02fc: Pulling fs layer\n",
            "6b5655404b42: Pulling fs layer\n",
            "8c4218ff02fc: Waiting\n",
            "6b5655404b42: Waiting\n",
            "82b1753306e8: Pulling fs layer\n",
            "cd9c6368b760: Waiting\n",
            "e4ac4998249a: Pulling fs layer\n",
            "82b1753306e8: Waiting\n",
            "80b5df9f6c2b: Pulling fs layer\n",
            "56b3f117226a: Pulling fs layer\n",
            "3955737a6d26: Pulling fs layer\n",
            "e4ac4998249a: Waiting\n",
            "80b5df9f6c2b: Waiting\n",
            "56b3f117226a: Waiting\n",
            "705fc9c9512a: Pulling fs layer\n",
            "3955737a6d26: Waiting\n",
            "6a539358c4fc: Pulling fs layer\n",
            "ddf32497ec0f: Pulling fs layer\n",
            "11affe872d1c: Pulling fs layer\n",
            "9c9b5ea4241f: Pulling fs layer\n",
            "705fc9c9512a: Waiting\n",
            "11affe872d1c: Waiting\n",
            "9c9b5ea4241f: Waiting\n",
            "ddf32497ec0f: Waiting\n",
            "6a539358c4fc: Waiting\n",
            "368214b0178a: Pulling fs layer\n",
            "09d8c3583c06: Pulling fs layer\n",
            "2f7fa3a19a92: Pulling fs layer\n",
            "7e4ce97fb1ab: Pulling fs layer\n",
            "368214b0178a: Waiting\n",
            "181d81d32d1e: Pulling fs layer\n",
            "335491c02640: Pulling fs layer\n",
            "2f7fa3a19a92: Waiting\n",
            "09d8c3583c06: Waiting\n",
            "7e4ce97fb1ab: Waiting\n",
            "181d81d32d1e: Waiting\n",
            "bec98e72f299: Pulling fs layer\n",
            "fc2b0675ff76: Pulling fs layer\n",
            "335491c02640: Waiting\n",
            "c40dd8202efc: Pulling fs layer\n",
            "bec98e72f299: Waiting\n",
            "fc2b0675ff76: Waiting\n",
            "be27a145ae74: Pulling fs layer\n",
            "9587d4acfcb9: Pulling fs layer\n",
            "be27a145ae74: Waiting\n",
            "c40dd8202efc: Waiting\n",
            "5a7e430f96ec: Verifying Checksum\n",
            "5a7e430f96ec: Download complete\n",
            "8a49af5f9845: Verifying Checksum\n",
            "8a49af5f9845: Download complete\n",
            "8a49af5f9845: Pull complete\n",
            "5a7e430f96ec: Pull complete\n",
            "f59d6eb2c245: Download complete\n",
            "4397f0d4f59f: Verifying Checksum\n",
            "4397f0d4f59f: Download complete\n",
            "a86d164c64ba: Download complete\n",
            "4e9f661082fc: Verifying Checksum\n",
            "4e9f661082fc: Download complete\n",
            "bec80a6b3a0e: Verifying Checksum\n",
            "bec80a6b3a0e: Download complete\n",
            "ff6c6c701902: Verifying Checksum\n",
            "ff6c6c701902: Download complete\n",
            "38ed7fbe6701: Verifying Checksum\n",
            "38ed7fbe6701: Download complete\n",
            "bdb7462cbb97: Download complete\n",
            "3f955f899066: Verifying Checksum\n",
            "3f955f899066: Download complete\n",
            "474075394bf2: Download complete\n",
            "27a2be24bf5e: Download complete\n",
            "fb00c809bb91: Verifying Checksum\n",
            "fb00c809bb91: Download complete\n",
            "22e12f30f4dd: Download complete\n",
            "69a2b9c38e00: Verifying Checksum\n",
            "69a2b9c38e00: Download complete\n",
            "459dee64b7ed: Download complete\n",
            "38c04d3213e1: Download complete\n",
            "988fc097120c: Download complete\n",
            "899a1f93590a: Verifying Checksum\n",
            "899a1f93590a: Download complete\n",
            "b1fa02a3ce23: Download complete\n",
            "ed2758f68444: Verifying Checksum\n",
            "ed2758f68444: Download complete\n",
            "5cce4eb8ba0e: Verifying Checksum\n",
            "5cce4eb8ba0e: Download complete\n",
            "a06c0a98fdc6: Verifying Checksum\n",
            "a06c0a98fdc6: Download complete\n",
            "6a2923762427: Download complete\n",
            "4f4fb700ef54: Verifying Checksum\n",
            "4f4fb700ef54: Download complete\n",
            "2b210285da11: Download complete\n",
            "5bc822689f39: Verifying Checksum\n",
            "5bc822689f39: Download complete\n",
            "10656710b432: Download complete\n",
            "0d157bd1c518: Verifying Checksum\n",
            "0d157bd1c518: Download complete\n",
            "ea623811982e: Download complete\n",
            "da3897cfef4f: Download complete\n",
            "6c46f635d9bf: Download complete\n",
            "cd9c6368b760: Verifying Checksum\n",
            "cd9c6368b760: Download complete\n",
            "f440049522de: Verifying Checksum\n",
            "f440049522de: Download complete\n",
            "4f87f4428c37: Verifying Checksum\n",
            "4f87f4428c37: Download complete\n",
            "8c4218ff02fc: Download complete\n",
            "6b5655404b42: Verifying Checksum\n",
            "6b5655404b42: Download complete\n",
            "e4ac4998249a: Verifying Checksum\n",
            "e4ac4998249a: Download complete\n",
            "80b5df9f6c2b: Verifying Checksum\n",
            "80b5df9f6c2b: Download complete\n",
            "56b3f117226a: Verifying Checksum\n",
            "56b3f117226a: Download complete\n",
            "dc8e02c573d5: Verifying Checksum\n",
            "dc8e02c573d5: Download complete\n",
            "3955737a6d26: Download complete\n",
            "6a539358c4fc: Verifying Checksum\n",
            "6a539358c4fc: Download complete\n",
            "705fc9c9512a: Verifying Checksum\n",
            "705fc9c9512a: Download complete\n",
            "ddf32497ec0f: Download complete\n",
            "11affe872d1c: Download complete\n",
            "368214b0178a: Verifying Checksum\n",
            "368214b0178a: Download complete\n",
            "9c9b5ea4241f: Verifying Checksum\n",
            "9c9b5ea4241f: Download complete\n",
            "09d8c3583c06: Verifying Checksum\n",
            "09d8c3583c06: Download complete\n",
            "2f7fa3a19a92: Download complete\n",
            "82b1753306e8: Verifying Checksum\n",
            "82b1753306e8: Download complete\n",
            "7e4ce97fb1ab: Download complete\n",
            "181d81d32d1e: Verifying Checksum\n",
            "181d81d32d1e: Download complete\n",
            "335491c02640: Verifying Checksum\n",
            "335491c02640: Download complete\n",
            "bec98e72f299: Verifying Checksum\n",
            "bec98e72f299: Download complete\n",
            "fc2b0675ff76: Download complete\n",
            "c40dd8202efc: Verifying Checksum\n",
            "c40dd8202efc: Download complete\n",
            "be27a145ae74: Download complete\n",
            "9587d4acfcb9: Download complete\n",
            "dc8e02c573d5: Pull complete\n",
            "f59d6eb2c245: Pull complete\n",
            "69a2b9c38e00: Pull complete\n",
            "4397f0d4f59f: Pull complete\n",
            "a86d164c64ba: Pull complete\n",
            "4e9f661082fc: Pull complete\n",
            "bec80a6b3a0e: Pull complete\n",
            "ff6c6c701902: Pull complete\n",
            "38ed7fbe6701: Pull complete\n",
            "bdb7462cbb97: Pull complete\n",
            "3f955f899066: Pull complete\n",
            "474075394bf2: Pull complete\n",
            "27a2be24bf5e: Pull complete\n",
            "fb00c809bb91: Pull complete\n",
            "22e12f30f4dd: Pull complete\n",
            "459dee64b7ed: Pull complete\n",
            "38c04d3213e1: Pull complete\n",
            "988fc097120c: Pull complete\n",
            "899a1f93590a: Pull complete\n",
            "b1fa02a3ce23: Pull complete\n",
            "ed2758f68444: Pull complete\n",
            "5cce4eb8ba0e: Pull complete\n",
            "a06c0a98fdc6: Pull complete\n",
            "6a2923762427: Pull complete\n",
            "4f4fb700ef54: Pull complete\n",
            "2b210285da11: Pull complete\n",
            "5bc822689f39: Pull complete\n",
            "10656710b432: Pull complete\n",
            "0d157bd1c518: Pull complete\n",
            "ea623811982e: Pull complete\n",
            "da3897cfef4f: Pull complete\n",
            "6c46f635d9bf: Pull complete\n",
            "cd9c6368b760: Pull complete\n",
            "f440049522de: Pull complete\n",
            "4f87f4428c37: Pull complete\n",
            "8c4218ff02fc: Pull complete\n",
            "6b5655404b42: Pull complete\n",
            "82b1753306e8: Pull complete\n",
            "e4ac4998249a: Pull complete\n",
            "80b5df9f6c2b: Pull complete\n",
            "56b3f117226a: Pull complete\n",
            "3955737a6d26: Pull complete\n",
            "705fc9c9512a: Pull complete\n",
            "6a539358c4fc: Pull complete\n",
            "ddf32497ec0f: Pull complete\n",
            "11affe872d1c: Pull complete\n",
            "9c9b5ea4241f: Pull complete\n",
            "368214b0178a: Pull complete\n",
            "09d8c3583c06: Pull complete\n",
            "2f7fa3a19a92: Pull complete\n",
            "7e4ce97fb1ab: Pull complete\n",
            "181d81d32d1e: Pull complete\n",
            "335491c02640: Pull complete\n",
            "bec98e72f299: Pull complete\n",
            "fc2b0675ff76: Pull complete\n",
            "c40dd8202efc: Pull complete\n",
            "be27a145ae74: Pull complete\n",
            "9587d4acfcb9: Pull complete\n",
            "Digest: sha256:52254d9919876dfcf3be3d14e1adfe9cc324a756b81048ac4f203ae8ade2e39a\n",
            "Status: Downloaded newer image for nvcr.io/nim/meta/llama-3.1-8b-instruct:latest\n",
            "nvcr.io/nim/meta/llama-3.1-8b-instruct:latest\n",
            "‚úÖ Docker container downloaded\n",
            "\n",
            "üì• Step 2: Checking Llama 3.1 8B model...\n",
            "üì• Downloading Llama 3.1 8B model (~15 GB)...\n",
            "   This will take 10-30 minutes depending on your connection\n",
            "   Download starting...\n",
            "\n",
            "‚úÖ Model download completed successfully!                    \n",
            "\n",
            "   Total files downloaded: 1\n",
            "   Total transferred: 14.96 GB\n",
            "\n",
            "üìÇ Model location: lora_tutorial/models/llama-3_1-8b-instruct/llama-3_1-8b-nemo_v1.0/llama3_1_8b.nemo\n",
            "üíæ Model size: 15.0 GB\n",
            "\n",
            "‚úÖ Setup complete!\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import glob\n",
        "import os\n",
        "import time\n",
        "import threading\n",
        "\n",
        "print(\"üì• Downloading workshop assets...\\n\")\n",
        "\n",
        "# Check prerequisites\n",
        "if not os.environ.get('NGC_API_KEY'):\n",
        "    print(\"‚ùå Please run the API key setup cell first\")\n",
        "else:\n",
        "    # 1. Download Docker container FIRST (usually faster)\n",
        "    print(\"üì• Step 1: Checking Docker container...\")\n",
        "    image = \"nvcr.io/nim/meta/llama-3.1-8b-instruct:latest\"\n",
        "    \n",
        "    # Simple check using docker images\n",
        "    result = subprocess.run(f\"docker images {image} --format '{{{{.Repository}}}}:{{{{.Tag}}}}'\", \n",
        "                          shell=True, capture_output=True, text=True)\n",
        "    \n",
        "    if image in result.stdout:\n",
        "        print(\"‚úÖ Docker container already downloaded\")\n",
        "    else:\n",
        "        print(\"üì• Pulling NIM Docker container...\")\n",
        "        # Docker login\n",
        "        os.system(f\"echo {os.environ['NGC_API_KEY']} | docker login nvcr.io -u \\\\$oauthtoken --password-stdin >/dev/null 2>&1\")\n",
        "        \n",
        "        # Pull container\n",
        "        result = os.system(f\"docker pull {image}\")\n",
        "        if result == 0:\n",
        "            print(\"‚úÖ Docker container downloaded\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  Container download failed - check Docker and NGC access\")\n",
        "    \n",
        "    # 2. Download Llama 3.1 8B model\n",
        "    print(\"\\nüì• Step 2: Checking Llama 3.1 8B model...\")\n",
        "    model_dir = \"lora_tutorial/models/llama-3_1-8b-instruct\"\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    \n",
        "    # Check if already downloaded\n",
        "    nemo_files = glob.glob(f\"{model_dir}/**/*.nemo\", recursive=True)\n",
        "    complete_model = None\n",
        "    \n",
        "    for nf in nemo_files:\n",
        "        size_gb = os.path.getsize(nf) / (1024**3)\n",
        "        if size_gb > 10:  # Full model should be ~15GB\n",
        "            complete_model = nf\n",
        "            break\n",
        "    \n",
        "    if complete_model:\n",
        "        print(\"‚úÖ Model already downloaded!\")\n",
        "        print(f\"üìÇ Location: {complete_model}\")\n",
        "        print(f\"üíæ Size: {os.path.getsize(complete_model) / (1024**3):.1f} GB\")\n",
        "    else:\n",
        "        print(\"üì• Downloading Llama 3.1 8B model (~15 GB)...\")\n",
        "        print(\"   This will take 10-30 minutes depending on your connection\")\n",
        "        print(\"   Download starting...\\n\")\n",
        "        \n",
        "        # Set environment variable and run download\n",
        "        os.environ['NGC_CLI_API_KEY'] = os.environ['NGC_API_KEY']\n",
        "        \n",
        "        # Build download command\n",
        "        cmd = f'cd {model_dir} && ../../../ngc-cli/ngc registry model download-version \"nvidia/nemo/llama-3_1-8b-nemo:1.0\" --org nvidia'\n",
        "        \n",
        "        # Run with subprocess to capture but simplify output\n",
        "        # Function to show simple progress indicator\n",
        "        download_complete = False\n",
        "        def show_progress():\n",
        "            symbols = [\"‚†ã\", \"‚†ô\", \"‚†π\", \"‚†∏\", \"‚†º\", \"‚†¥\", \"‚†¶\", \"‚†ß\", \"‚†á\", \"‚†è\"]\n",
        "            i = 0\n",
        "            while not download_complete:\n",
        "                print(f\"\\r{symbols[i % len(symbols)]} Downloading... (this may take 10-30 minutes)\", end=\"\", flush=True)\n",
        "                time.sleep(0.5)\n",
        "                i += 1\n",
        "        \n",
        "        # Start progress indicator in background\n",
        "        progress_thread = threading.Thread(target=show_progress)\n",
        "        progress_thread.start()\n",
        "        \n",
        "        # Run download\n",
        "        process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        stdout, stderr = process.communicate()\n",
        "        result = process.returncode\n",
        "        \n",
        "        # Stop progress indicator\n",
        "        download_complete = True\n",
        "        progress_thread.join()\n",
        "        print(\"\\r\" + \" \" * 60 + \"\\r\", end=\"\")  # Clear the progress line\n",
        "        \n",
        "        if result == 0:\n",
        "            # Extract summary info from stdout\n",
        "            if \"Download status: Completed\" in stdout:\n",
        "                print(\"‚úÖ Model download completed successfully!\\n\")\n",
        "                # Try to extract useful info\n",
        "                for line in stdout.split('\\n'):\n",
        "                    if \"Total files downloaded:\" in line or \"Total transferred:\" in line:\n",
        "                        print(f\"   {line.strip()}\")\n",
        "            else:\n",
        "                print(\"‚úÖ Model download complete!\")\n",
        "            \n",
        "            # Find the downloaded file\n",
        "            nemo_files = glob.glob(f\"{model_dir}/**/*.nemo\", recursive=True)\n",
        "            if nemo_files:\n",
        "                print(f\"\\nüìÇ Model location: {nemo_files[0]}\")\n",
        "                print(f\"üíæ Model size: {os.path.getsize(nemo_files[0]) / (1024**3):.1f} GB\")\n",
        "        else:\n",
        "            print(\"\\n‚ùå Download failed. Please check:\")\n",
        "            print(\"   - Your NGC API key is valid\")\n",
        "            print(\"   - You have internet connectivity\")\n",
        "            print(\"   - You have enough disk space (need ~15GB)\")\n",
        "\n",
        "print(\"\\n‚úÖ Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 4: Verify Setup\n",
        "\n",
        "Let's make sure everything is ready for the workshop:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Verifying setup...\n",
            "\n",
            "‚úÖ Model downloaded\n",
            "‚úÖ Docker container\n",
            "‚úÖ NGC API Key\n",
            "‚úÖ NVIDIA API Key\n",
            "\n",
            "üì° Cloud API: ‚úÖ Connected\n",
            "\n",
            "üéâ All set! You're ready for the NIM workshop!\n",
            "\n",
            "üìÇ Model location: lora_tutorial/models/llama-3_1-8b-instruct/llama-3_1-8b-nemo_v1.0/llama3_1_8b.nemo\n",
            "üíæ Model size: 15.0 GB\n",
            "üê≥ Container: nvcr.io/nim/meta/llama-3.1-8b-instruct:latest\n"
          ]
        }
      ],
      "source": [
        "print(\"üîç Verifying setup...\\n\")\n",
        "\n",
        "# Quick checks - check if any .nemo file exists in the model directory or subdirectories\n",
        "import glob\n",
        "nemo_files = glob.glob(\"lora_tutorial/models/llama-3_1-8b-instruct/**/*.nemo\", recursive=True)\n",
        "# Check if we have a complete model (>10GB)\n",
        "model_downloaded = False\n",
        "for nf in nemo_files:\n",
        "    if os.path.getsize(nf) / (1024**3) > 10:\n",
        "        model_downloaded = True\n",
        "        break\n",
        "\n",
        "checks = {\n",
        "    \"Model downloaded\": model_downloaded,\n",
        "    \"Docker container\": bool(subprocess.run(['docker', 'images', '-q', 'nvcr.io/nim/meta/llama-3.1-8b-instruct:latest'],\n",
        "                                       capture_output=True, text=True).stdout.strip()),\n",
        "    \"NGC API Key\": bool(os.environ.get('NGC_API_KEY')),\n",
        "    \"NVIDIA API Key\": bool(os.environ.get('NVIDIA_API_KEY'))\n",
        "}\n",
        "\n",
        "# Print results\n",
        "for item, status in checks.items():\n",
        "    print(f\"{'‚úÖ' if status else '‚ùå'} {item}\")\n",
        "\n",
        "# Test cloud API connection\n",
        "try:\n",
        "    import requests\n",
        "    headers = {\"Authorization\": f\"Bearer {os.environ.get('NVIDIA_API_KEY', '')}\"}\n",
        "    response = requests.get(\"https://integrate.api.nvidia.com/v1/models\", headers=headers, timeout=5)\n",
        "    print(f\"\\nüì° Cloud API: {'‚úÖ Connected' if response.status_code == 200 else f'‚ö†Ô∏è  Status {response.status_code}'}\")\n",
        "except:\n",
        "    print(\"\\nüì° Cloud API: ‚ö†Ô∏è  Could not test connection\")\n",
        "\n",
        "# Summary\n",
        "if all(checks.values()):\n",
        "    print(\"\\nüéâ All set! You're ready for the NIM workshop!\")\n",
        "    # Find the actual model file (look in subdirectories)\n",
        "    complete_models = [nf for nf in nemo_files if os.path.getsize(nf) / (1024**3) > 10]\n",
        "    if complete_models:\n",
        "        print(f\"\\nüìÇ Model location: {complete_models[0]}\")\n",
        "        print(f\"üíæ Model size: {os.path.getsize(complete_models[0]) / (1024**3):.1f} GB\")\n",
        "    else:\n",
        "        print(\"\\nüìÇ Model location: Not found - please run the download cell\")\n",
        "    print(\"üê≥ Container: nvcr.io/nim/meta/llama-3.1-8b-instruct:latest\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Some components missing - please check above\")\n",
        "    \n",
        "# Create data directory for later use\n",
        "os.makedirs(\"lora_tutorial/data\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéØ Next Steps\n",
        "\n",
        "### Model Information\n",
        "- **Model**: Llama 3.1 8B Instruct \n",
        "- **Format**: Standard NeMo checkpoint (`.nemo` file)\n",
        "- **Location**: `lora_tutorial/models/llama-3_1-8b-instruct/*.nemo` (exact filename depends on download)\n",
        "\n",
        "### What's Next?\n",
        "1. **01_NIM_API_Tutorial.ipynb** - Learn to use cloud-hosted NIMs\n",
        "2. **02_Local_NIM_Deployment.ipynb** - Deploy NIMs locally with Docker\n",
        "3. **03_LoRA_Training.ipynb** - Fine-tune the model with LoRA\n",
        "4. **04_Deploy_LoRA_with_NIM.ipynb** - Deploy your fine-tuned model\n",
        "\n",
        "### Troubleshooting\n",
        "\n",
        "**If download fails:**\n",
        "- Verify your NGC API key is correct\n",
        "- Check your internet connection\n",
        "- Try running the download cell again (downloads can be resumed)\n",
        "\n",
        "**Docker issues:**\n",
        "- Make sure Docker daemon is running\n",
        "- On Linux: `sudo systemctl start docker`\n",
        "- Test with: `docker run hello-world`\n",
        "\n",
        "**Model format:**\n",
        "The Llama 3.1 model uses standard NeMo format:\n",
        "- Single `.nemo` file containing all weights and configuration\n",
        "- Compatible with NeMo training scripts without modifications\n",
        "\n",
        "---\n",
        "\n",
        "**Ready to start?** Open `01_NIM_API_Tutorial.ipynb` to begin the workshop\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
